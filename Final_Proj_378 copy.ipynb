{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wv\n",
    "import scipy.signal as ss\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.naive_bayes as sknb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_csv('train.csv')\n",
    "y = td['Genre'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_test = \"test\"\n",
    "\n",
    "audio_data_list_test = []\n",
    "sampling_rate_list_test = []\n",
    "\n",
    "# Iterate over test data\n",
    "for filename in os.listdir(directory_test):\n",
    "    # Loads all the .wav files in the traning set\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory_test, filename)\n",
    "        audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Append the audio data and sampling rate to the lists\n",
    "        audio_data_list_test.append(audio_data)\n",
    "        sampling_rate_list_test.append(sampling_rate)\n",
    "\n",
    "# Now we can use the audio data and sampling rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"train\"\n",
    "\n",
    "audio_data_list_unsorted = []\n",
    "sampling_rate_list_unsorted = []\n",
    "\n",
    "filename_list = []\n",
    "\n",
    "# Iterate over training data\n",
    "for filename in os.listdir(directory):\n",
    "    # Loads all the .wav files in the traning set\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Append the audio data and sampling rate to the lists\n",
    "        audio_data_list_unsorted.append(audio_data)\n",
    "        sampling_rate_list_unsorted.append(sampling_rate)\n",
    "\n",
    "        filename_list.append(filename)\n",
    "\n",
    "# here, we sort normalized_features so our y data matches it\n",
    "zipped_lists = zip(filename_list, audio_data_list_unsorted, sampling_rate_list_unsorted)\n",
    "zipped_sorted = sorted(zipped_lists, key=lambda x: x[0][5:8])\n",
    "audio_data_list = [x for _, x, _ in zipped_sorted]\n",
    "sampling_rate_list = [x for _, _, x in zipped_sorted]\n",
    "\n",
    "# Now we can use the audio data and sampling rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathers the frequency information of a song\n",
    "fft_list = []\n",
    "for song in audio_data_list:\n",
    "    fft_list.append(np.fft.fft(song))\n",
    "    \n",
    "fft_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    fft_list_test.append(np.fft.fft(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes energy of each song\n",
    "energy_list = []\n",
    "for song in audio_data_list:\n",
    "    energy_list.append(np.sum(np.square(song)))\n",
    "    \n",
    "energy_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    energy_list_test.append(np.sum(np.square(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the variance and mean of each song\n",
    "variance_list = []\n",
    "expectation_list = []\n",
    "for song in audio_data_list:\n",
    "    variance_list.append(np.var(song))\n",
    "    expectation_list.append(np.mean(song))\n",
    "    \n",
    "variance_list_test = []\n",
    "expectation_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    variance_list_test.append(np.var(song))\n",
    "    expectation_list_test.append(np.mean(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the tempo of each song\n",
    "tempo_list = []\n",
    "for i in range(0,len(audio_data_list)):\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio_data_list[i], sr=sampling_rate_list[i])\n",
    "    tempo_list.append(tempo)\n",
    "\n",
    "tempo_list_test = []\n",
    "for i in range(0,len(audio_data_list_test)):\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio_data_list_test[i], sr=sampling_rate_list_test[i])\n",
    "    tempo_list_test.append(tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the zero cross rate of each song\n",
    "zero_cross_rate_list = []\n",
    "for song in audio_data_list:\n",
    "    zero_cross_rate_list.append(np.median(librosa.feature.zero_crossing_rate(song)))\n",
    "\n",
    "zero_cross_rate_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    zero_cross_rate_list_test.append(np.median(librosa.feature.zero_crossing_rate(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the FFT entropy of each song\n",
    "fft_entrp_list = []\n",
    "for fft in fft_list:\n",
    "    fft_entrp_list.append(entropy(np.absolute(fft)))\n",
    "\n",
    "fft_entrp_list_test = []\n",
    "for fft in fft_list_test:\n",
    "    fft_entrp_list_test.append(entropy(np.absolute(fft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers the MFCCs of a song\n",
    "mfcc_list = []\n",
    "for song in audio_data_list:\n",
    "    mfcc_list.append(np.fft.fft(song))\n",
    "    \n",
    "mfcc_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    mfcc_list_test.append(np.fft.fft(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets entropy of MFCCs\n",
    "mfcc_entrp_list = []\n",
    "for mfcc in mfcc_list:\n",
    "    mfcc_entrp_list.append(entropy(np.absolute(mfcc)))\n",
    "\n",
    "mfcc_entrp_list_test = []\n",
    "for mfcc in mfcc_list_test:\n",
    "    mfcc_entrp_list_test.append(entropy(np.absolute(mfcc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_compare(song, data):\n",
    "    \"\"\"\n",
    "    Sees how similar the fft of the songs are, higher number means more overlap\n",
    "    song is one song and data is all the songs to compare song to\n",
    "    can be used for time or for freq domain info\n",
    "    \"\"\"\n",
    "    flipped_song = np.flip(song)\n",
    "    convolution_sim_list = []\n",
    "    for audio in data:\n",
    "        sum = 0\n",
    "        for i in range(0,len(audio)):\n",
    "            sum += audio[i]*flipped_song[i]\n",
    "        convolution_sim_list.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the Feature Matrix\n",
    "feature_matrix = np.column_stack((energy_list, variance_list, expectation_list, tempo_list, zero_cross_rate_list, fft_entrp_list, mfcc_entrp_list))\n",
    "feature_matrix_test = np.column_stack((energy_list_test, variance_list_test, expectation_list_test, tempo_list_test, zero_cross_rate_list_test, fft_entrp_list_test, mfcc_entrp_list_test))\n",
    "\n",
    "# Step 2: Normalize the Feature Matrix\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(feature_matrix)\n",
    "normalized_features_test = scaler.fit_transform(feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SVD test\n",
    "# # Center the data\n",
    "# nf_c = normalized_features - normalized_features.mean()\n",
    "\n",
    "\n",
    "# # Take SVD\n",
    "# (nf_u, nf_s, nf_vh) = np.linalg.svd(nf_c)\n",
    "# # 2-D Approximation\n",
    "\n",
    "# # the pca transform matrix for reducing dimensionality to 2\n",
    "# nf_v_approx = np.transpose(nf_vh[:2])\n",
    "\n",
    "# # the dimensionality reduced transformed data\n",
    "# nf_pca = np.dot(nf_c, nf_v_approx)\n",
    "\n",
    "# # Plot the approximation\n",
    "# plt.scatter(nf_pca[:, 0], nf_pca[:, 1])\n",
    "\n",
    "# for i, tag in enumerate(Y):\n",
    "#     plt.annotate(tag[0][0], (nf_pca[i, 0], nf_pca[i, 1]))\n",
    "# plt.title(\"Types of Cancer\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reneewrysinski/Documents/Elec-378-Final/.venv/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:595: UserWarning: n_components is too large: it will be set to 7\n",
      "  warnings.warn(\n",
      "/Users/reneewrysinski/Documents/Elec-378-Final/.venv/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/reneewrysinski/Documents/Elec-378-Final/.venv/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:595: UserWarning: n_components is too large: it will be set to 7\n",
      "  warnings.warn(\n",
      "/Users/reneewrysinski/Documents/Elec-378-Final/.venv/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Apply ICA\n",
    "ica = FastICA(n_components=10, random_state=42)\n",
    "independent_components = ica.fit_transform(normalized_features)\n",
    "independent_components_test = ica.fit_transform(normalized_features_test)\n",
    "\n",
    "# Step 4: Clustering and Classifying\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(independent_components, y)\n",
    "\n",
    "# Map cluster labels to genres\n",
    "predicted_genres = clf.predict(independent_components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = sknb.GaussianNB()\n",
    "nb_model.fit(normalized_features, y)\n",
    "predicted_genres = nb_model.predict(normalized_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for filename, genre in zip(os.listdir(directory_test), predicted_genres):\n",
    "    predictions.append((filename,genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the list nurmerically since the dict is random\n",
    "sorted_data = sorted(predictions, key=lambda x: x[0][4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts it into a .csv file (finally!!!!)\n",
    "df = pd.DataFrame(sorted_data, columns=['ID', 'genre'])\n",
    "df.to_csv('test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

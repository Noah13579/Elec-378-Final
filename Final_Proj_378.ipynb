{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wv\n",
    "import scipy.signal as ss\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to my training set should change\n",
    "directory = \"/Users/noahvilla/Downloads/Dataset/train\"\n",
    "\n",
    "audio_data_list = []\n",
    "sampling_rate_list = []\n",
    "\n",
    "# Iterate over training data\n",
    "for filename in os.listdir(directory):\n",
    "    # Loads all the .wav files in the traning set\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Append the audio data and sampling rate to the lists\n",
    "        audio_data_list.append(audio_data)\n",
    "        sampling_rate_list.append(sampling_rate)\n",
    "\n",
    "# Now we can use the audio data and sampling rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathers the frequency information of a song\n",
    "fft_list = []\n",
    "for song in audio_data_list:\n",
    "    fft_list.append(np.fft.fft(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes energy of each song\n",
    "energy_list = []\n",
    "for song in audio_data_list:\n",
    "    energy_list.append(np.sum(np.square(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the variance and mean of each song\n",
    "variance_list = []\n",
    "expectation_list = []\n",
    "for song in audio_data_list:\n",
    "    variance_list.append(np.var(song))\n",
    "    expectation_list.append(np.mean(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_list = []\n",
    "for i in range(0,len(audio_data_list)):\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio_data_list[i], sr=sampling_rate_list[i])\n",
    "    tempo_list.append(tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n"
     ]
    }
   ],
   "source": [
    "zero_cross_rate_list = []\n",
    "for song in audio_data_list:\n",
    "    zero_cross_rate_list.append(np.median(librosa.feature.zero_crossing_rate(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_entrp_list = []\n",
    "for fft in fft_list:\n",
    "    fft_entrp_list.append(entropy(np.absolute(fft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_compare(song, data):\n",
    "    \"\"\"\n",
    "    Sees how similar the fft of the songs are, higher number means more overlap\n",
    "    song is one song and data is all the songs to compare song to\n",
    "    can be used for time or for freq domain info\n",
    "    \"\"\"\n",
    "    flipped_song = np.flip(song)\n",
    "    convolution_sim_list = []\n",
    "    for audio in data:\n",
    "        sum = 0\n",
    "        for i in range(0,len(audio)):\n",
    "            sum += audio[i]*flipped_song[i]\n",
    "        convolution_sim_list.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the Feature Matrix\n",
    "feature_matrix = np.column_stack((energy_list, variance_list, expectation_list, tempo_list, zero_cross_rate_list, fft_entrp_list))\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(feature_matrix)\n",
    "\n",
    "# Apply ICA\n",
    "ica = FastICA(n_components=10, random_state=42)\n",
    "independent_components = ica.fit_transform(normalized_features)\n",
    "\n",
    "# Cluster\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "clusters = kmeans.fit_predict(independent_components)\n",
    "\n",
    "# Step 5: Evaluation\n",
    "# You may need to manually inspect the clusters to see if they align with the known genres\n",
    "\n",
    "# Assign genres to clusters (these clusters are just groups, the labels may not be correct, should listen to some of these songs)\n",
    "genre_mapping = {\n",
    "    0: 'blues',\n",
    "    1: 'classical',\n",
    "    8: 'country',\n",
    "    3: 'disco',\n",
    "    4: 'hiphop',\n",
    "    5: 'jazz',\n",
    "    6: 'metal',\n",
    "    7: 'pop',\n",
    "    2: 'reggae',\n",
    "    9: 'rock'\n",
    "}\n",
    "\n",
    "# Map cluster labels to genres\n",
    "predicted_genres = [genre_mapping[cluster] for cluster in clusters]\n",
    "\n",
    "# Print predicted genres for each song in the required format\n",
    "print(\"ID,Genre\")\n",
    "for filename, genre in zip(os.listdir(directory), predicted_genres):\n",
    "    print(f\"{filename},{genre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_genres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/noahvilla/Downloads/Dataset\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mpredicted_genres\u001b[49m})\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_genres' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'ID': os.listdir('/Users/noahvilla/Downloads/Dataset'), 'genre': predicted_genres})\n",
    "df.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

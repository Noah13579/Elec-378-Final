{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wv\n",
    "import scipy.signal as ss\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.naive_bayes as sknb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_csv('./train.csv')\n",
    "y = td['Genre'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to my training set should change\n",
    "directory_test = \"/Users/noahvilla/Downloads/Dataset/test\"\n",
    "\n",
    "audio_data_list_test = []\n",
    "sampling_rate_list_test = []\n",
    "\n",
    "# Iterate over training data\n",
    "for filename in os.listdir(directory_test):\n",
    "    # Loads all the .wav files in the traning set\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory_test, filename)\n",
    "        audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Append the audio data and sampling rate to the lists\n",
    "        audio_data_list_test.append(audio_data)\n",
    "        sampling_rate_list_test.append(sampling_rate)\n",
    "\n",
    "# Now we can use the audio data and sampling rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to my training set should change\n",
    "directory = \"/Users/noahvilla/Downloads/Dataset/train\"\n",
    "\n",
    "audio_data_list = []\n",
    "sampling_rate_list = []\n",
    "\n",
    "# Iterate over training data\n",
    "for filename in os.listdir(directory):\n",
    "    # Loads all the .wav files in the traning set\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Append the audio data and sampling rate to the lists\n",
    "        audio_data_list.append(audio_data)\n",
    "        sampling_rate_list.append(sampling_rate)\n",
    "\n",
    "# Now we can use the audio data and sampling rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathers the frequency information of a song\n",
    "fft_list = []\n",
    "for song in audio_data_list:\n",
    "    fft_list.append(np.fft.fft(song))\n",
    "    \n",
    "fft_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    fft_list_test.append(np.fft.fft(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes energy of each song\n",
    "energy_list = []\n",
    "for song in audio_data_list:\n",
    "    energy_list.append(np.sum(np.square(song)))\n",
    "    \n",
    "energy_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    energy_list_test.append(np.sum(np.square(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the variance and mean of each song\n",
    "variance_list = []\n",
    "expectation_list = []\n",
    "for song in audio_data_list:\n",
    "    variance_list.append(np.var(song))\n",
    "    expectation_list.append(np.mean(song))\n",
    "    \n",
    "variance_list_test = []\n",
    "expectation_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    variance_list_test.append(np.var(song))\n",
    "    expectation_list_test.append(np.mean(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_list = []\n",
    "for i in range(0,len(audio_data_list)):\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio_data_list[i], sr=sampling_rate_list[i])\n",
    "    tempo_list.append(tempo)\n",
    "\n",
    "tempo_list_test = []\n",
    "for i in range(0,len(audio_data_list_test)):\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio_data_list_test[i], sr=sampling_rate_list_test[i])\n",
    "    tempo_list_test.append(tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cross_rate_list = []\n",
    "for song in audio_data_list:\n",
    "    zero_cross_rate_list.append(np.median(librosa.feature.zero_crossing_rate(song)))\n",
    "\n",
    "zero_cross_rate_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    zero_cross_rate_list_test.append(np.median(librosa.feature.zero_crossing_rate(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_entrp_list = []\n",
    "for fft in fft_list:\n",
    "    fft_entrp_list.append(entropy(np.absolute(fft)))\n",
    "\n",
    "fft_entrp_list_test = []\n",
    "for fft in fft_list_test:\n",
    "    fft_entrp_list_test.append(entropy(np.absolute(fft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_list = []\n",
    "for song in audio_data_list:\n",
    "    mfcc_list.append(librosa.feature.mfcc(y = song, n_mfcc = 15))\n",
    "\n",
    "mfcc_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    mfcc_list_test.append(librosa.feature.mfcc(y = song, n_mfcc = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_mfcc = []\n",
    "for mfcc in mfcc_list:\n",
    "    condensed_mfcc.append(np.average(mfcc))\n",
    "\n",
    "condensed_mfcc_test = []\n",
    "for mfcc in mfcc_list_test:\n",
    "    condensed_mfcc_test.append(np.average(mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mfcc = []\n",
    "for mfcc in mfcc_list:\n",
    "    var_mfcc.append(np.var(mfcc))\n",
    "\n",
    "var_mfcc_test = []\n",
    "for mfcc in mfcc_list_test:\n",
    "    var_mfcc_test.append(np.var(mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroid_list = []\n",
    "spectral_rolloff_list = []\n",
    "spectral_bandwidth_list = []\n",
    "spectral_contrast_list = []\n",
    "spectral_flatness_list = []\n",
    "onset_list = []\n",
    "beat_list = []\n",
    "beat_eng_list = []\n",
    "chrom_list = []\n",
    "for song in audio_data_list:\n",
    "    spectral_centroid_list.append(librosa.feature.spectral_centroid(y = song))\n",
    "    spectral_rolloff_list.append(librosa.feature.spectral_rolloff(y = song))\n",
    "    spectral_flatness_list.append(librosa.feature.spectral_flatness(y = song))\n",
    "    onset = librosa.onset.onset_strength(y = song)\n",
    "    onset_list.append(onset)\n",
    "    _, beat = librosa.beat.beat_track(y = song)\n",
    "    beat_list.append(beat)\n",
    "    beat_eng_list.append(onset[beat])\n",
    "    chrom_list.append(librosa.feature.chroma_stft(y = song))\n",
    "    spectral_bandwidth_list.append(librosa.feature.spectral_bandwidth(y = song))\n",
    "    spectral_contrast_list.append(librosa.feature.spectral_contrast(y = song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroid_list_test = []\n",
    "spectral_rolloff_list_test = []\n",
    "spectral_bandwidth_list_test = []\n",
    "spectral_contrast_list_test = []\n",
    "spectral_flatness_list_test = []\n",
    "onset_list_test = []\n",
    "beat_list_test = []\n",
    "beat_eng_list_test = []\n",
    "chrom_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    spectral_centroid_list_test.append(librosa.feature.spectral_centroid(y = song))\n",
    "    spectral_rolloff_list_test.append(librosa.feature.spectral_rolloff(y = song))\n",
    "    spectral_flatness_list_test.append(librosa.feature.spectral_flatness(y = song))\n",
    "    onset = librosa.onset.onset_strength(y = song)\n",
    "    onset_list_test.append(onset)\n",
    "    _, beat = librosa.beat.beat_track(y = song)\n",
    "    beat_list_test.append(beat)\n",
    "    beat_eng_list_test.append(onset[beat])\n",
    "    chrom_list_test.append(librosa.feature.chroma_stft(y = song))\n",
    "    spectral_bandwidth_list_test.append(librosa.feature.spectral_bandwidth(y = song))\n",
    "    spectral_contrast_list_test.append(librosa.feature.spectral_contrast(y = song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeat(songs):\n",
    "    expectation = []\n",
    "    var = []\n",
    "    entrp = []\n",
    "    for song in songs:\n",
    "        expectation.append(np.average(np.absolute(song)))\n",
    "        var.append(np.var(song))\n",
    "        entrp.append(entropy(song))\n",
    "    return expectation, var, entrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroid_exp_list, spectral_centroid_var_list, spectral_centroid_ent_list = getFeat(spectral_centroid_list)\n",
    "spectral_rolloff_exp_list, spectral_rolloff_var_list, spectral_rolloff_ent_list = getFeat(spectral_rolloff_list)\n",
    "spectral_bandwidth_exp_list, spectral_bandwidth_var_list, spectral_bandwidth_ent_list = getFeat(spectral_bandwidth_list)\n",
    "spectral_flatness_exp_list, spectral_flatness_var_list, spectral_flatness_ent_list = getFeat(spectral_flatness_list)\n",
    "spectral_contrast_exp_list, spectral_contrast_var_list, spectral_contrast_ent_list = getFeat(spectral_contrast_list)\n",
    "chrom_exp_list, chrom_var_list, chrom_ent_list = getFeat(chrom_list)\n",
    "beat_eng_exp_list, beat_eng_var_list, beat_eng_ent_list = getFeat(beat_eng_list)\n",
    "onset_exp_list, onset_var_list, onset_ent_list = getFeat(onset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroid_exp_list_test, spectral_centroid_var_list_test, spectral_centroid_ent_list_test = getFeat(spectral_centroid_list_test)\n",
    "spectral_rolloff_exp_list_test, spectral_rolloff_var_list_test, spectral_rolloff_ent_list_test = getFeat(spectral_rolloff_list_test)\n",
    "spectral_bandwidth_exp_list_test, spectral_bandwidth_var_list_test, spectral_bandwidth_ent_list_test = getFeat(spectral_bandwidth_list_test)\n",
    "spectral_flatness_exp_list_test, spectral_flatness_var_list_test, spectral_flatness_ent_list_test = getFeat(spectral_flatness_list_test)\n",
    "spectral_contrast_exp_list_test, spectral_contrast_var_list_test, spectral_contrast_ent_list_test = getFeat(spectral_contrast_list_test)\n",
    "chrom_exp_list_test, chrom_var_list_test, chrom_ent_list_test = getFeat(chrom_list_test)\n",
    "beat_eng_exp_list_test, beat_eng_var_list_test, beat_eng_ent_list_test = getFeat(beat_eng_list_test)\n",
    "onset_exp_list_test, onset_var_list_test, onset_ent_list_test = getFeat(onset_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_contrast_ent_exp_list = []\n",
    "spectral_contrast_ent_var_list = []\n",
    "for item in spectral_contrast_ent_list:\n",
    "    spectral_contrast_ent_exp_list.append(np.average(item))\n",
    "    spectral_contrast_ent_var_list.append(np.var(item))\n",
    "\n",
    "chrom_ent_exp_list = []\n",
    "chrom_ent_var_list = []\n",
    "for item in chrom_ent_list:\n",
    "    chrom_ent_exp_list.append(np.average(item))\n",
    "    chrom_ent_var_list.append(np.var(item))\n",
    "\n",
    "go_through = (energy_list, variance_list, expectation_list, tempo_list, zero_cross_rate_list, \n",
    "              fft_entrp_list, condensed_mfcc, var_mfcc, fft_mean_list, fft_var_list, \n",
    "              spectral_centroid_exp_list, spectral_centroid_var_list, spectral_rolloff_exp_list, spectral_rolloff_var_list, spectral_bandwidth_exp_list, \n",
    "              spectral_bandwidth_var_list, spectral_flatness_exp_list, spectral_flatness_var_list, spectral_contrast_exp_list, spectral_contrast_var_list, \n",
    "              spectral_contrast_ent_exp_list, spectral_contrast_ent_var_list, chrom_exp_list, chrom_var_list, chrom_ent_exp_list, \n",
    "              chrom_ent_var_list, beat_eng_exp_list, beat_eng_var_list, beat_eng_ent_list, onset_exp_list, \n",
    "              onset_var_list, onset_ent_list)\n",
    "\n",
    "def replace_nan_with_zero(array):\n",
    "    array[np.isnan(array)] = 0\n",
    "    return array\n",
    "\n",
    "# Apply the function to each array in the tuple\n",
    "go_through_cleaned = tuple(replace_nan_with_zero(np.array(arr)) for arr in go_through)\n",
    "\n",
    "spectral_contrast_ent_exp_list_test = []\n",
    "spectral_contrast_ent_var_list_test = []\n",
    "for item in spectral_contrast_ent_list_test:\n",
    "    spectral_contrast_ent_exp_list_test.append(np.average(item))\n",
    "    spectral_contrast_ent_var_list_test.append(np.var(item))\n",
    "\n",
    "chrom_ent_exp_list_test = []\n",
    "chrom_ent_var_list_test = []\n",
    "for item in chrom_ent_list_test:\n",
    "    chrom_ent_exp_list_test.append(np.average(item))\n",
    "    chrom_ent_var_list_test.append(np.var(item))\n",
    "\n",
    "go_through_test = (energy_list_test, variance_list_test, expectation_list_test, tempo_list_test, zero_cross_rate_list_test, \n",
    "              fft_entrp_list_test, condensed_mfcc_test, var_mfcc_test, fft_mean_list_test, fft_var_list_test, \n",
    "              spectral_centroid_exp_list_test, spectral_centroid_var_list_test, spectral_rolloff_exp_list_test, spectral_rolloff_var_list_test, spectral_bandwidth_exp_list_test, \n",
    "              spectral_bandwidth_var_list_test, spectral_flatness_exp_list_test, spectral_flatness_var_list_test, spectral_contrast_exp_list_test, spectral_contrast_var_list_test, \n",
    "              spectral_contrast_ent_exp_list_test, spectral_contrast_ent_var_list_test, chrom_exp_list_test, chrom_var_list_test, chrom_ent_exp_list_test, \n",
    "              chrom_ent_var_list_test, beat_eng_exp_list_test, beat_eng_var_list_test, beat_eng_ent_list_test, onset_exp_list_test, \n",
    "              onset_var_list_test, onset_ent_list_test)\n",
    "\n",
    "go_through_cleaned_test = tuple(replace_nan_with_zero(np.array(arr)) for arr in go_through_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_compare(song, data):\n",
    "    \"\"\"\n",
    "    Sees how similar the fft of the songs are, higher number means more overlap\n",
    "    song is one song and data is all the songs to compare song to\n",
    "    can be used for time or for freq domain info\n",
    "    \"\"\"\n",
    "    flipped_song = np.flip(song)\n",
    "    convolution_sim_list = []\n",
    "    for audio in data:\n",
    "        sum = 0\n",
    "        for i in range(0,len(audio)):\n",
    "            sum += audio[i]*flipped_song[i]\n",
    "        convolution_sim_list.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the Feature Matrix\n",
    "feature_matrix = np.column_stack(go_through_cleaned)\n",
    "feature_matrix_test = np.column_stack(go_through_cleaned_test)\n",
    "\n",
    "# Step 2: Normalize the Feature Matrix\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(feature_matrix)\n",
    "normalized_features_test = scaler.fit_transform(feature_matrix_test)\n",
    "\n",
    "# Step 3: Apply ICA\n",
    "ica = FastICA(n_components=10, random_state=42)\n",
    "independent_components = ica.fit_transform(normalized_features)\n",
    "independent_components_test = ica.fit_transform(normalized_features_test)\n",
    "\n",
    "# Step 4: Clustering and Classifying\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(independent_components, y)\n",
    "\n",
    "# Map cluster labels to genres\n",
    "predicted_genres = clf.predict(independent_components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = sknb.GaussianNB()\n",
    "nb_model.fit(normalized_features, y)\n",
    "predicted_genres = nb_model.predict(normalized_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for filename, genre in zip(os.listdir(directory_test), predicted_genres):\n",
    "    predictions.append((filename,genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the list nurmerically since the dict is random\n",
    "sorted_data = sorted(predictions, key=lambda x: x[0][5:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts it into a .csv file (finally!!!!)\n",
    "df = pd.DataFrame(sorted_data, columns=['ID', 'genre'])\n",
    "df.to_csv('/Users/noahvilla/Downloads/Dataset/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

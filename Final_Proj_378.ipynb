{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wv\n",
    "import scipy.signal as ss\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_csv('/Users/noahvilla/Downloads/Dataset/train.csv')\n",
    "y = td['Genre'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to my training set should change\n",
    "directory_test = \"/Users/noahvilla/Downloads/Dataset/test\"\n",
    "\n",
    "audio_data_list_test = []\n",
    "sampling_rate_list_test = []\n",
    "\n",
    "# Iterate over training data\n",
    "for filename in os.listdir(directory_test):\n",
    "    # Loads all the .wav files in the traning set\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory_test, filename)\n",
    "        audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Append the audio data and sampling rate to the lists\n",
    "        audio_data_list_test.append(audio_data)\n",
    "        sampling_rate_list_test.append(sampling_rate)\n",
    "\n",
    "# Now we can use the audio data and sampling rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to my training set should change\n",
    "directory = \"/Users/noahvilla/Downloads/Dataset/train\"\n",
    "\n",
    "audio_data_list = []\n",
    "sampling_rate_list = []\n",
    "\n",
    "# Iterate over training data\n",
    "for filename in os.listdir(directory):\n",
    "    # Loads all the .wav files in the traning set\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Append the audio data and sampling rate to the lists\n",
    "        audio_data_list.append(audio_data)\n",
    "        sampling_rate_list.append(sampling_rate)\n",
    "\n",
    "# Now we can use the audio data and sampling rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathers the frequency information of a song\n",
    "fft_list = []\n",
    "for song in audio_data_list:\n",
    "    fft_list.append(np.fft.fft(song))\n",
    "    \n",
    "fft_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    fft_list_test.append(np.fft.fft(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes energy of each song\n",
    "energy_list = []\n",
    "for song in audio_data_list:\n",
    "    energy_list.append(np.sum(np.square(song)))\n",
    "    \n",
    "energy_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    energy_list_test.append(np.sum(np.square(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the variance and mean of each song\n",
    "variance_list = []\n",
    "expectation_list = []\n",
    "for song in audio_data_list:\n",
    "    variance_list.append(np.var(song))\n",
    "    expectation_list.append(np.mean(song))\n",
    "    \n",
    "variance_list_test = []\n",
    "expectation_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    variance_list_test.append(np.var(song))\n",
    "    expectation_list_test.append(np.mean(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_list = []\n",
    "for i in range(0,len(audio_data_list)):\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio_data_list[i], sr=sampling_rate_list[i])\n",
    "    tempo_list.append(tempo)\n",
    "\n",
    "tempo_list_test = []\n",
    "for i in range(0,len(audio_data_list_test)):\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio_data_list_test[i], sr=sampling_rate_list_test[i])\n",
    "    tempo_list_test.append(tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cross_rate_list = []\n",
    "for song in audio_data_list:\n",
    "    zero_cross_rate_list.append(np.median(librosa.feature.zero_crossing_rate(song)))\n",
    "\n",
    "zero_cross_rate_list_test = []\n",
    "for song in audio_data_list_test:\n",
    "    zero_cross_rate_list_test.append(np.median(librosa.feature.zero_crossing_rate(song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_entrp_list = []\n",
    "for fft in fft_list:\n",
    "    fft_entrp_list.append(entropy(np.absolute(fft)))\n",
    "\n",
    "fft_entrp_list_test = []\n",
    "for fft in fft_list_test:\n",
    "    fft_entrp_list_test.append(entropy(np.absolute(fft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_compare(song, data):\n",
    "    \"\"\"\n",
    "    Sees how similar the fft of the songs are, higher number means more overlap\n",
    "    song is one song and data is all the songs to compare song to\n",
    "    can be used for time or for freq domain info\n",
    "    \"\"\"\n",
    "    flipped_song = np.flip(song)\n",
    "    convolution_sim_list = []\n",
    "    for audio in data:\n",
    "        sum = 0\n",
    "        for i in range(0,len(audio)):\n",
    "            sum += audio[i]*flipped_song[i]\n",
    "        convolution_sim_list.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the Feature Matrix\n",
    "feature_matrix = np.column_stack((energy_list, variance_list, expectation_list, tempo_list, zero_cross_rate_list, fft_entrp_list))\n",
    "feature_matrix_test = np.column_stack((energy_list_test, variance_list_test, expectation_list_test, tempo_list_test, zero_cross_rate_list_test, fft_entrp_list_test))\n",
    "\n",
    "# Step 2: Normalize the Feature Matrix\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(feature_matrix)\n",
    "normalized_features_test = scaler.fit_transform(feature_matrix_test)\n",
    "\n",
    "# Step 3: Apply ICA\n",
    "ica = FastICA(n_components=10, random_state=42)\n",
    "independent_components = ica.fit_transform(normalized_features)\n",
    "independent_components_test = ica.fit_transform(normalized_features_test)\n",
    "\n",
    "# Step 4: Clustering and Classifying\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(independent_components, y)\n",
    "\n",
    "# Map cluster labels to genres\n",
    "predicted_genres = clf.predict(independent_components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for filename, genre in zip(os.listdir(directory), predicted_genres):\n",
    "    predictions.append((filename,genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the list nurmerically since the dict is random\n",
    "sorted_data = sorted(predictions, key=lambda x: x[0][5:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts it into a .csv file (finally!!!!)\n",
    "df = pd.DataFrame(sorted_data, columns=['ID', 'genre'])\n",
    "df.to_csv('/Users/noahvilla/Downloads/Dataset/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
